import pandas as pd
import time
import sys
import os
import argparse


"""
This script is used to generate ROC curves, AUC, and confusion matrices based
on a variety of user inputs.

It is designed to be specifically utilized with the other scripts in this
project which generate the prerequisite CSVs for this script.
Namely, those scripts are:
main.py (utilized by the Sybil container image).
cleanup_nlst_for_sybil.py (requires nlst clinical data, either via CDAS or the
Cancer Imaging Archive).
"""

# Constants
N_PREDICTION_YEARS = 6

OPERATOR_DICT = {
    'e'     :   '==',
    'g'     :   '>',
    'l'     :   '<',
    'ge'    :   '>=',
    'le'    :   '<='
}

def main():
    print("Sybil NLST Filter for ROC curve drawing and AUC calculation")

    # ArgParse library is used to manage command line arguments.`
    parser = argparse.ArgumentParser()
    parser.add_argument("actual", help="a CSV file generated by \
        cleanup_nlst_for_sybil.py which contains the actual values regarding \
        the presence of cancer n years after a given CT scan.")
    parser.add_argument("prediction", help="a CSV file generated by main.py \
        (utilized by Sybil container image) which contains the prediction \
        values generated by Sybil regarding the probability of cancer n years \
        after a given CT scan.")
    parser.add_argument('-o', "--outdir", help="A directory in which to \
        generate the output.", nargs = '?', default=os.getcwd())
    parser.add_argument("filters", help="any number of filters to apply to the \
        data, formated as such: property_name:value:operator, e.g. age:65:ge. \
        Operator options: \
        e -> equal, g -> greater than, l -> less than, \
        ge -> greater than or equal to, le -> less than or equal to", 
        nargs='*')
    args = parser.parse_args()
    print("Actual:", args.actual)
    print("Prediction: ", args.prediction)
    print("Output directory: ", args.outdir)
    print("Filters: ", args.filters)
    return
    # Read in CSVs
    actual = pd.read_csv(args.actual)
    prediction = pd.read_csv(args.prediction)

    # Filter the actual CSV
    actual_filtered = parse_filters(actual, args.filters)

    # Initialize new actual dataframe
    actual_aligned: list[list[int]] = [[]] * N_PREDICTION_YEARS
    prediction_aligned: list[list[float]] = [[]] * N_PREDICTION_YEARS

    # Iterate through the filtered CSV
    for index, row in actual_filtered.iterrows():
        query_str = ""
        # Find entries with the same PID
        query_str += "pid == " + row["pid"] + " and "
        # Find entries with the same screening year
        query_str += "study_year == " + row["study_yr"]
        queried_prediction = prediction.query(query_str)
        n_predictions = queried_prediction.shape[0]
        print(query_str)
        print(queried_prediction)

        # There are multiple CT scans per individual patient per study year.
        # Because of this, the actual data and prediction data don't align.
        # Thus, new actual data columns must be generated to match the
        # prediction data.
        for year in range(N_PREDICTION_YEARS):
            # Add the appropriate number of repeated actual values to align with
            # the number of predictions.
            column_name = "canc_yr" + str(year)
            actual_value = row[column_name]
            repeated_actual = [actual_value] * n_predictions
            actual_aligned[year].extend(repeated_actual)

            # Add the predictions to their appropriate column as well.
            column_name = "pred_yr" + str(year)
            current_prediction = queried_prediction[column_name].tolist()
        
        if index == 3: ### TODO: remove
            prediction_aligned[year].extend(current_prediction)
            break ###
    
    # Create DataFrames
    # These dataframes can now be compared-
    # year1 of the actual aligned df can be compared with year1 of the
    # prediction aligned df, year2 with year2, and so on.
    column_names = ["year" + str(i) for i in range(1,N_PREDICTION_YEARS+1)]
    actual_aligned_df = pd.DataFrame(
        actual_aligned, columns = column_names
    )
    prediction_aligned_df = pd.DataFrame(
        prediction_aligned, columns = column_names
    )

def parse_filters(df: pd.DataFrame, filters: list[str]) -> pd.DataFrame:
    query_str = ""
    for index in range(len(filters)):
        parse_list = filters[index].split(':')
        appended_str = ""
        
        # Add property name
        appended_str += parse_list[0] + " "

        # Add operator
        if parse_list[2] not in OPERATOR_DICT.keys():
            raise Exception("Invalid operator. Options: e, g, l, ge, le.")
        appended_str += OPERATOR_DICT[parse_list[2]] + " "

        # Add value
        appended_str += parse_list[1]

        # Add 'and'
        if index != len(filters) - 1:
            appended_str += " and "

        query_str += appended_str
    print(query_str) ### TODO: remove
    return df.query(query_str)      

def generate_multi_roc(actual, prediction):
    # TODO: 
    # The image file will be a PNG portraying all 6 ROC curves, with labels 
    # that include the Area Under Curve (AUC) calculations.
    
    print("Generating Multi-ROC curve...")
    
    plt.figure(figsize = (5, 5), dpi = 100)
    for year in actual:
        current_actual = actual[year].tolist()
        current_prediction = prediction[year].tolist()

        fpr, tpr, threshold = roc_curve(current_actual, current_prediction)
        roc_auc = auc(fpr, tpr)

        plt.plot(fpr, tpr, linestyle = "-", label = "AUC = " + str(roc_auc))

    plt.xlabel("1 - Specificity")
    plt.ylabel("Sensitivity")

    file_name = "multi_roc.png"
    plt.savefig(args.outdir + "/" + file_name)

def generate_confusion_matrices(actual, prediction,
    cutoffs = [i / 10.0 for i in range(1,10)]):
    # TODO: Confusion matrix requires:
    # True positive, true negative, false positive, false negative.
    # Create such a table for every probability cutoff.
    
    print("Generating confusion matrices...")

    for year in actual:
        csv_name = "confusion_matrices_" + column + ".csv"
        with open(args.outdir + "/" + csv_name, 'w') as current_csv:
            for cutoff in cutoffs:
                current.csv.write("Probability cutoff,=,{cutoff}\n")
                tp = 0 # True Positive
                tn = 0 # True Negative
                fp = 0 # False Positive
                fn = 0 # False Negative
                for index, current_actual in enumerate(actual[year]):
                    current_prediction = prediction[year][index]
                    guess_positive: bool = current_prediction >= cutoff
                    if   current_actual == 1 and     guess_positive:
                        tp += 1
                    elif current_actual == 0 and not guess_positive:
                        tn += 1
                    elif current_actual == 0 and     guess_positive:
                        fp += 1
                    elif current_actual == 1 and not guess_positive:
                        fn += 1
                current_csv.write(",actual_positive,actual_negative\n")
                current_csv.write(f"prediction_positive,{tp},{fp}\n")
                current_csv.write(f"prediction_negative,{fn},{tn}\n\n")

start = time.perf_counter()
main()
end = time.perf_counter()
print(f"{sys.argv[0]} Completed in {end - start:0.4f} seconds.")

