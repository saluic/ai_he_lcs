import pandas as pd
import time
import sys
import os
import argparse


"""
This script is used to generate ROC curves, AUC, and confusion matrices based
on a variety of user inputs.

It is designed to be specifically utilized with the other scripts in this
project which generate the prerequisite CSVs for this script.
Namely, those scripts are:
main.py (utilized by the Sybil container image).
cleanup_nlst_for_sybil.py (requires nlst clinical data, either via CDAS or the
Cancer Imaging Archive).
"""

# Constants
N_PREDICTION_YEARS = 6

OPERATOR_DICT = {
    'e'     :   '==',
    'g'     :   '>',
    'l'     :   '<',
    'ge'    :   '>=',
    'le'    :   '<='
}

DEFAULT_CUTOFFS = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

def main():
    print("Sybil NLST Filter for ROC curve drawing and AUC calculation")

    # ArgParse library is used to manage command line arguments.`
    parser = argparse.ArgumentParser(
        epilog="Example: sybil_nlst_filter_for_roc.py \
        path/to/actual.csv path/to/prediction.csv -o output_dir \
        -f gender:2:e race:2:e -c 0.25 0.5 0.75"
    )
    parser.add_argument("actual", help="a CSV file generated by \
        cleanup_nlst_for_sybil.py which contains the actual values regarding \
        the presence of cancer n years after a given CT scan.")
    parser.add_argument("prediction", help="a CSV file generated by main.py \
        (utilized by Sybil container image) which contains the prediction \
        values generated by Sybil regarding the probability of cancer n years \
        after a given CT scan.")
    parser.add_argument('-o', "--outdir", help="A directory in which to \
        generate the output. \
        Default: script current working directory.",
        default=os.getcwd())
    parser.add_argument('-f', "--filters", help="Any number of filters to apply to the \
            data, formated as such: property_name:value:operator, e.g. race:2:e. \
        Operator options: \
        e -> equal, g -> greater than, l -> less than, \
        ge -> greater than or equal to, le -> less than or equal to. \
        Default: no filters.", 
        nargs='+', default=[])
    parser.add_argument('-c', '--cutoffs', help="Any number of probability \
        cutoffs to be used for the generation of multiple confusion matrices. \
        Default: " + str(DEFAULT_CUTOFFS), type=float,
        nargs='+', default=DEFAULT_CUTOFFS)
    args = parser.parse_args()
    print("Actual:", args.actual)
    print("Prediction: ", args.prediction)
    print("Output directory: ", args.outdir)
    print("Filters: ", args.filters)
    print("Cutoffs: ", args.cutoffs)

    # Read in CSVs
    actual = pd.read_csv(args.actual)
    ### prediction = pd.read_csv(args.prediction)

    # Filter the actual CSV
    actual_filtered = parse_filters(actual, args.filters)
    return ### TODO: remove

    # Initialize new actual dataframe
    actual_aligned: list[list[int]] = [[]] * N_PREDICTION_YEARS
    prediction_aligned: list[list[float]] = [[]] * N_PREDICTION_YEARS

    # Iterate through the filtered CSV
    for index, row in actual_filtered.iterrows():
        query_str = ""
        # Find entries with the same PID
        query_str += "pid == " + row["pid"] + " and "
        # Find entries with the same screening year
        query_str += "study_year == " + row["study_yr"]
        queried_prediction = prediction.query(query_str)
        n_predictions = queried_prediction.shape[0]
        print(query_str)
        print(queried_prediction)

        # There are multiple CT scans per individual patient per study year.
        # Because of this, the actual data and prediction data don't align.
        # Thus, new actual data columns must be generated to match the
        # prediction data.
        for year in range(N_PREDICTION_YEARS):
            # Add the appropriate number of repeated actual values to align with
            # the number of predictions.
            column_name = "canc_yr" + str(year)
            actual_value = row[column_name]
            repeated_actual = [actual_value] * n_predictions
            actual_aligned[year].extend(repeated_actual)

            # Add the predictions to their appropriate column as well.
            column_name = "pred_yr" + str(year)
            current_prediction = queried_prediction[column_name].tolist()
        
        if index == 3: ### TODO: remove
            prediction_aligned[year].extend(current_prediction)
            break ###
    
    # Create DataFrames
    # These dataframes can now be compared-
    # year1 of the actual aligned df can be compared with year1 of the
    # prediction aligned df, year2 with year2, and so on.
    column_names = ["year" + str(i) for i in range(1,N_PREDICTION_YEARS+1)]
    actual_aligned_df = pd.DataFrame(
        actual_aligned, columns = column_names
    )
    prediction_aligned_df = pd.DataFrame(
        prediction_aligned, columns = column_names
    )

    # Execute function to generate multi-ROC curve, generates PNG.
    generate_multi_roc(
        actual_aligned_df,
        prediction_aligned_df,
        args.outdir
    )

    # Execute function to generate multiple confusion matrices, generates one
    # CSV file per prediction year.
    generate_confusion_matrices(
        actual_aligned_df,
        prediction_aligned_df,
        args.outdir,
        args.cutoffs
    )

def parse_filters(df: pd.DataFrame, filters: list[str]) -> pd.DataFrame:
    # This function applies user-selected filters to given DataFrame.
    # Example: race:2:e will return a DataFrame which contains only rows where
    # the associated patient has a race=2 (Black).
    # EXAMPLE BREAKDOWN:
    # race:2:e
    # race = the column to use for filtering
    # 2 = the value used for comparison
    # e = the chosen comparison operator, in this case 'equal to'
    # The filter therefore selects only individuals whose race is equal to 2.

    query_str = ""
    for index in range(len(filters)):
        parse_list = filters[index].split(':')
        appended_str = ""
        
        # Add property name
        # Ensure valid property name
        if parse_list[0] not in df.columns:
            columns_str = ', '.join(df.columns)
            raise Exception("Invalid property name found in filter " \
                f"{filters[index]}: {parse_list[0]}. " \
                "\nPlease select a property name from the following list: " \
                f"\n{columns_str}")
        appended_str += parse_list[0] + " "

        # Add operator
        # Ensure valid operator
        if parse_list[2] not in OPERATOR_DICT.keys():
            operators_str = ', '.join(OPERATOR_DICT.keys())
            raise Exception("Invalid operator found in filter " \
                f"({filters[index]}): {parse_list[2]}. " \
                "\nPlease select an operator from the following list: " \
                f"\n{operators_str}")
        appended_str += OPERATOR_DICT[parse_list[2]] + " "

        # Add value
        appended_str += parse_list[1]

        # Add 'and'
        if index != len(filters) - 1:
            appended_str += " and "

        query_str += appended_str
    print(query_str) ### TODO: remove
    return df.query(query_str)      

def generate_multi_roc(actual, prediction, out_dir):
    # This function uses actual and prediction values to create a multi-ROC
    # curve PNG image, which it then stores in a specified output directory.
    # The generated image is labeled such that each curve is identified by year,
    # and area under curve (AUC) value is provided for each curve.
    
    print("Generating Multi-ROC curve...")
    
    plt.figure(figsize = (5, 5), dpi = 100)
    for year in actual:
        current_actual = actual[year].tolist()
        current_prediction = prediction[year].tolist()

        fpr, tpr, threshold = roc_curve(current_actual, current_prediction)
        roc_auc = auc(fpr, tpr)

        plt.plot(fpr, tpr, linestyle = "-", label = "AUC = " + str(roc_auc))

    plt.xlabel("1 - Specificity")
    plt.ylabel("Sensitivity")

    file_name = "multi_roc.png"
    plt.savefig(out_dir + "/" + file_name)

def generate_confusion_matrices(actual, prediction, out_dir, cutoffs):
    # This function uses actual and prediction values to create multiple
    # confusion matrices
    # TODO: Confusion matrix requires:
    # True positive, true negative, false positive, false negative.
    # Create such a table for every probability cutoff.
    
    print("Generating confusion matrices...")

    for year in actual:
        csv_name = "confusion_matrices_" + column + ".csv"
        with open(out_dir + "/" + csv_name, 'w') as current_csv:
            for cutoff in cutoffs:
                current.csv.write("Probability cutoff,=,{cutoff}\n")
                tp = 0 # True Positive
                tn = 0 # True Negative
                fp = 0 # False Positive
                fn = 0 # False Negative
                for index, current_actual in enumerate(actual[year]):
                    current_prediction = prediction[year][index]
                    guess_positive: bool = current_prediction >= cutoff
                    if   current_actual == 1 and     guess_positive:
                        tp += 1
                    elif current_actual == 0 and not guess_positive:
                        tn += 1
                    elif current_actual == 0 and     guess_positive:
                        fp += 1
                    elif current_actual == 1 and not guess_positive:
                        fn += 1
                current_csv.write(",actual_positive,actual_negative\n")
                current_csv.write(f"prediction_positive,{tp},{fp}\n")
                current_csv.write(f"prediction_negative,{fn},{tn}\n")
                # Calculate descriptive values
                sensitivity = 0
                specificity = 0
                ppv = 0 # Positive Predictive Value
                current_csv.write(f"Sensitivity,=,{sensitivity}\n")
                current_csv.write(f"Specificity,=,{specificity}\n")
                current_csv.write(f"PPV,=,{ppv}\n\n"

start = time.perf_counter()
main()
end = time.perf_counter()
print(f"{sys.argv[0]} Completed in {end - start:0.4f} seconds.")

